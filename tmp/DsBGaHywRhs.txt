The man widely seen as the godfather of artificial intelligence has quit his job at Google, warning of the dangers of AI. Dr. Geoffrey Hinton's pioneering research on deep learning and neural networks has paved the way for current AI systems like ChatGPT. But in a lengthy interview with the New York Times, Dr. Hinton said he now regretted his work and is worried that AI technology will flood the Internet with misinformation. Google responded in a statement saying, we remain committed to a responsible approach to AI. Dr. Hinton has been telling the BBC how these systems can know so much. The kind of intelligence we're developing is very different from the intelligence we have. We're biological systems and these are digital systems. And the big difference is that with digital systems, you have many copies of the same set of weights, the same model of the world. And all these copies can learn separately, but share their knowledge instantly. So it's as if you had 10,000 people and whenever one person learned something, everybody automatically knew it. And that's how these channels can know so much more than any one person. Well, Dr. Hinton also told the BBC the rate of progress is worrying. Right now, what we're seeing is things like GPT-4 eclipses a person in the amount of general knowledge it has and eclipses them by a long way. In terms of reasoning, it's not as good, but it does already do simple reasoning. And given the rate of progress, we expect things to get better quite fast. So we need to worry about that. Right now, they're not more intelligent than us, as far as I can tell. But I think they soon may be. Earlier, I spoke to Junaid Mubeen, author of Mathematical Intelligence. I asked what he makes of the AI warning. I think this one is to be taken seriously because of where it's coming from. I wouldn't take Elon Musk's own warnings particularly seriously because he's not an AI expert. Geoffrey Hinton, on the other hand, is one of the pioneers of artificial intelligence. And he's also been very specific in laying out a hierarchy of risks and concerns. And so he mentions the threats that AI pose to the workforce and to the spread of misinformation. But the concerns that he's raised around existential risk, I think, are to be taken seriously. And I think it's important to recognize that those risks are not premised on AI becoming conscious or gaining sentience. We're not talking about a terminator doomday scenario. But it's the idea that these technologies are able to amass information and process information so effectively that if you put them in the hands of bad human actors, they can wreak all kinds of havoc. And I think that is something we all need to pay attention to. So tell us a bit more about that, because he referred, didn't he, to bad actors who would use AI for bad things. So tell us a bit more about what you think he means by that. So I think one of the challenges with these chatbots is we don't fundamentally understand how they work. We know that they absorb large amounts of information, and then you can input a prompt, and it will give you an output. It might write an essay for you. It might generate an image or a video. And so the challenge is that as these systems become more complex, we can issue them with certain tasks. So I might ask a chatbot to go online and find the cheapest train ticket for me, and I might give it access to my bank account. And it will be able to carry out that task, and the stakes there seem fairly low. But you can imagine in a different context where the stakes are a lot higher, these systems might be weaponized to carry out a whole range of tasks. And they will execute those tasks in ways that we don't fully understand. And I think the concern that people like Geoffrey Hinton have is that there could be unintended consequences. These systems behave in ways that are very different to humans. So there's no real account for how they will go about achieving their objectives, and especially if those objectives are rooted in some kind of malicious intent. So if an authoritarian leader, for example, says to a chatbot system, help me to reassert my grip on a population. There's no real knowing how a very complex computer-based system would go about achieving that, what kinds of manipulations it might employ. And so the lack of transparency is something that we really need to be concerned about. A couple of months ago, more than 1,000 tech leaders called for a six-month moratorium on the development of new AI systems because of what they said was the tech posing a profound risk to society and humanity. I mean, is it too late? It may well be. I think we have to adopt some spirit of optimism and recognize that we do have a huge degree of human intelligence as well. And now more than ever, we need to summon that. And one thing that Geoffrey Hinton does emphasize is that digital intelligence, the kind espoused by these chatbots, is very different to human intelligence. And that may present an opportunity for us to tap into our own human strengths and understand how we can behave and cooperate with one another in ways that might allow us to regulate these technologies and rein them in. But I will say Geoffrey Hinton has been working on these technologies for several decades. There are many within the space that have been issuing these warnings for several years. So his own warning does seem to be coming quite late in the day. And there is a sense that maybe the genie's out of the bottle now and there's no real accounting for what happens next.